# -*- coding: utf-8 -*-
"""Copie de MATHS_4_DEBERNARDI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B4na7q47WYFiGQPW67NxlxW5LwWEcoYz

* 5.1, 5.2

# **Évaluation du risque par une méthode de Monte Carlo et tests par permutations**

L'objectif de ce TP est de regarder le test de comparaison de deux moyennes à partir de deux échantillons indépendants.
Les données forment un vecteur $(x_1,\ldots, x_m, y_1,\ldots, y_n)$ de longueur $m+n$. Elles concernent l'effet d'un traitement médical sur $m+n$ patients. Les $m=13$ premiers patients ont reçu le médicament $A$, qui est le traitement de référence. Les $n=16$ autres patients ont reçu le médicament $B$, qui est le nouveau traitement. L'objectif de l'étude est de savoir si ce médicament $B$ est plus efficace que le traitement de référence.

Les données sont :
$x_{1:m}^\text{obs} = (-3.06, -0.71, 11.99, 1.42, 1.84, 13.1, 4.19, -8.06, -3.96, -2.24, 9.61, 3.47, 3.77)$ et $y_{1:n}^\text{obs} = (12.57, 7.44, 2.97, 10.35, 10.24, 9.89, 9.07, 8.23, 4.42, 2.9, 2.44, 0.49, 3.51, -3.05, 18.25, 12.29)$.

On modélise ces données $(x_1,\ldots, x_m, y_1,\ldots, y_n)$ par le vecteur de variables aléatoires $(X_1,\ldots, X_m, Y_1,\ldots, Y_n)$. On suppose que ces $m+n$ variables sont indépendantes, que les $X_i$ ont tous même loi, d'espérance $\mu_X$ et que les $Y_j$ ont tous même loi, d'espérance
$\mu_X+\Delta$.

On s'intéresse aux  hypothèses $H_0: \Delta \le 0 \quad \textit{vs} \quad H_1~: \Delta>0$.
"""

import numpy as np
import scipy.stats as stats
import plotly.graph_objects as go
from sklearn.utils import resample

"""## **Partie 1 : Test de Student sous hypothèse gaussienne**

### **1.1** Justifier du choix de $\Delta \le 0$ comme hypothèse nulle.

On cherche à savoir si le traitement B est plus efficace que le A. Sous l'hypothèse ($\Delta \le 0$), l'efficacité moyenne du traitement B n'est pas meilleure que celle du traitement A. On pose donc comme hypothèse nulle $H_0 : \Delta \le 0$ afin de ne pas avoir de perte d'efficacité en cas d'erreur (autrement dit, on préfère conserver A si on est pas suffisamment certain de la supériorité de B). 

On cherchera par la suite à calculer $P(H_1 | H_0)$ la probabilité qui nous indique à quel point on aurait tort de croire en l'hypothèse $H_0$ plutôt qu'en $H_1$.

### **1.2** Justifier du choix de la statistique de test T.

T est une bonne statistique de test car :

* (a) On peut calculer T sans connaître la vraie valeur de $\theta = \{\mu_X, \sigma^2, \Delta\}$ .
    * T dépend uniquement des observations.

* (b) Le comportement de T sous ($H_0$) et sous ($H_1$) est différent.
    * On attend de T qu'il soit $\le$ 0 lorsque $\Delta \le 0$ et > 0 lorsque $\Delta > 0$.

* (c) La loi de $T$ sous les pires cas est entièrement connue.
    * Dans le pire cas $\Delta = 0$, $T$ suit une loi de Student à $m+n-2$ degrés de liberté.

* (d) Le comportement de T est connu lorsqu'on s'éloigne de ($H_0$).
    * T est croissant en $\Delta$.

### **1.3** Justifier que la zone de rejet soit de la forme [c; +$\infty$] où c est une constante à déterminer.

On rejette l'hypothèse nulle après un test de taille $\alpha$ si $P(H_1 | H_0) > 1 - \alpha $. Soit $c \in \textbf{R}^+$

On a : $\Delta > 0 \iff T > 0$.

$P(H_1 | H_0) = P(\Delta > 0 | H_0) = P(T > 0 | H_0) \geq P(T>c)$

 et on a : $ P(T>c) > 1 - \alpha \implies P(H_1 | H_0) > 1 - \alpha$ 

D'où une zone de rejet de la forme [c; +$\infty$].

### **1.4** On note $\Phi_{m+n-2}$ la fonction de répartition de la loi de Student à $m+n-2$ degrés de liberté. Montrer que, si l'on fixe la taille du test à $\alpha$, il faut choisir $c=\Phi_{m+n-2}^{-1}(1-\alpha)$.

On veut $P(H_1 | H_0) = \alpha$

 $\iff P(\bar Y - \bar X > \epsilon) = \alpha$

$ \iff P(\bar Y - \bar X < \epsilon) = 1- \alpha$

$\iff P(T < c) = 1- \alpha$ avec c = $\frac{\epsilon}{\sqrt{S_p^2\left(\frac1m+\frac1n\right)}}$

$\iff \Phi_{m+n-2}(c) = 1-\alpha$

$\iff c=\Phi_{m+n-2}^{-1}(1-\alpha)$

### **1.5** Ecrire une fonction (sans boucle for explicite), nommée calculeT qui calcule la valeur observée de T, à partir de deux entrées : le vecteur des $x_i$ et le vecteur des $y_i$. Que vaut la valeur observée $t^{obs}$ ici ?
"""

def calculeT(x1, x2):
    """
    Modélise un test pour comparer deux moyennes sous hypothèse gaussienne.

    Hypothèse nulle    : H0 (mu1 >= mu2)
    Hypothèse à tester : H1 (mu1 <  mu2)
    P-valeur           : valeur maximum du pourcentage au-delà duquel je ne
                         peux plus rejeter H1.

    Parameters
    ----------
    x1 : array-like
    x2 : array-like
    """
    assert len(x1) > 0, 'x1 doit contenir des données'
    assert len(x2) > 0, 'x2 doit contenir des données'

    mu1 = x1.mean()
    mu2 = x2.mean()

    # on calcule la somme des variances pour éviter de diviser par la taille
    # puis de re-multiplier lors du calcul de S
    var1 = ((x1 - mu1)**2).sum()
    var2 = ((x2 - mu2)**2).sum()


    # degré de liberté du test de Student
    student_law_degree = (len(x1) + len(x2) - 2)

    S = (var1 + var2) / student_law_degree
    denom = np.sqrt(S * (1/len(x1) + 1/len(x2)))

    return (mu2 - mu1) / denom

def calculePvalue(t_obs, student_law_degree):
    """
    Calcule la p-value associée au test valeur observée d'un test
    """
    return 1 - stats.t.cdf(t_obs, student_law_degree)

"""* Tests de vérification en fonction de la valeur de $\Delta$"""

def tests_selon_delta(deltas):
    for delta in deltas:
        x1 = np.random.normal(delta, 1, size=(1000))
        x2 = np.random.normal(0, 1, size=(1000))

        t_obs = calculeT(x1, x2)
        p_value = calculePvalue(t_obs, len(x1)+len(x2)-2)

        print(f"* (mu2-mu1) = {delta}")
        print(f"\t t_obs={t_obs}")
        print(f"\t p_value={p_value}\n")

tests_selon_delta(deltas=[1, -1, 0.1, -0.1])

"""* Test de vérification de la valeur de la $p$-value en fonction de delta"""

start = -5
end = 5
t_obs_range = np.arange(start, end)

values = []
for t_obs in t_obs_range:
    values.append(calculePvalue(t_obs, 27))

fig = go.Figure(
    data=[
        go.Scatter(
            y=values
        )
    ],
    layout={
        'legend': {
            'orientation': 'h'
        },
    }
)
fig.show()

# ---
# données utilisées dans la partie 1
# ---
x1 = np.array([
    -3.06, -0.71, 11.99, 1.42, 1.84, 13.1, 4.19, -8.06, -3.96, -2.24,
    9.61, 3.47, 3.77
])
x2 = np.array([
    12.57, 7.44, 2.97, 10.35, 10.24, 9.89, 9.07, 8.23, 4.42, 2.9,
    2.44, 0.49, 3.51, -3.05, 18.25, 12.29
])

student_law_degree = len(x1)+len(x2)-2

t_obs = calculeT(x1, x2)
print(f"Réponse question 5, t_obs={t_obs}")

"""# **1.6** En utilisant les fonctions de scipy.stats, calculer $c$ dans notre cas si $\alpha = 0.05$. Quelle décision prend le test de Student ?"""

print(f"Réponse question 6, c={stats.t.ppf(0.95, student_law_degree)}")

"""On a $t^{obs} > c$, on prend donc la décision alternative, en rejetant l'hypothèse nulle. En effet, on a calculé précédement que si l'hypothèse nulle $H_0$ est vraie, on a $P(T > c) =\alpha = 0.05$, il est donc plus probable que $H_0$ soit fausse.

# **1.7** Montrer que la $p$-value est donnée ici par $p(X,Y) = 1 - \Phi_{m+n-2}(T)$. Quelle est la valeur observée de la $p$-value ?

On cherche $p$ la valeur du plus petit test que nos données nous permettent de passer. Autrement dit, on cherche à minimiser $\alpha = P(T > c)$ d'après **1.4**. Comme $P(T > c) =P(T \geq c)$ est décroissant en $c$, il suffit de choisir $c = T$ pour minimiser $\alpha$. De plus, on sait que $c =1 - \Phi^{-1}_{m+n-2}(\alpha) \iff  \alpha = 1 - \Phi_{m+n-2}(c) $ d'où $p = 1 - \Phi_{m+n-2}(T)$.
"""

p_value = calculePvalue(t_obs, student_law_degree)
print(f"Réponse question 7, p_value={p_value}")

"""# **Partie 2 : Étude de la puissance du test de Student**

## **2.1** $\star$ Montrer que la loi de $T$ ne dépend pas de $\mu_X$, mais uniquement de $\Delta$ et $\sigma^2$. Dans toute la suite, on fixera $\mu_X = 0.92$ si on a besoin d'une valeur numérique.

On note X$_1$ $\sim N\Big(\mu_1, \sigma^2\Big)$, Y$_1$ $\sim N\Big(\mu_1 + \Delta, \sigma^2\Big)$

et X$_2$ = X$_1$ + $\epsilon$, et Y$_2$ = Y$_1$ + $\epsilon$ avec $\epsilon \in \mathbb{R}$. (On a donc $\mu_2 = \mu_1 + \epsilon$)

On note également $T_1 = \frac{\bar Y_1 - \bar X_1}{\sqrt{S_{1,p}^2\left(\frac1m+\frac1n\right)}}$ et $T_2 = \frac{\bar Y_2 - \bar X_2}{\sqrt{S_{2,p}^2\left(\frac1m+\frac1n\right)}}$.


On veut montrer $T_1 = T_2$.

On a :

$\bar{X_2} = \frac{1}{m} \sum_{i=1}^m X_{2,i} = \frac{1}{m} \sum_{i=1}^m (X_{1,i} + \epsilon) = \bar{X_1} + \epsilon $

$\bar{Y_2} = \frac{1}{n} \sum_{j=1}^n Y_{2,j} = \frac{1}{n} \sum_{j=1}^n (Y_{1,j} + \epsilon) = \bar{Y_1} + \epsilon $

$S_{X_2}^2 = \frac{1}{m-1}\sum_{i=1}^m(X_{2,i} - \bar{X_2}) = \frac{1}{m-1}\sum_{i=1}^m(X_{1,i} - \bar{X_1}) = S_{X_1}^2$

$S_{Y_2}^2 = \frac{1}{n-1}\sum_{j=1}^n(Y_{2,j} - \bar{Y_2}) = \frac{1}{n-1}\sum_{j=1}^n(Y_{1,j} - \bar{Y_1}) = S_{Y_1}^2$

d'où $S_{1,p}^2 = S_{2,p}^2$ et $T_1 = T_2$.
$\square$

## **2.2** Écrire une fonction nommée `simuleT` qui prend en entrée les valeurs de $\Delta$ et $\sigma^2$ et qui fait les choses suivantes:
* elle simule un vecteur $(X_1,\ldots, X_m)$ et un vecteur $(Y_1,\ldots, Y_n)$, de longueurs respectives $m=13$ et $n=17$;
* elle calcule et renvoie la valeur de $T$ de l'équation (3), en utilisant la fonction `calculeT`.
"""

def genereDonnees(delta, sigma, n_samples_x1=13, n_samples_x2=17):
    # paramètre fixé
    mean_x1 = 0.92

    x1 = np.random.normal(mean_x1, sigma, (n_samples_x1, 1))
    x2 = np.random.normal(mean_x1 + delta, sigma, (n_samples_x2, 1))

    return x1, x2

def simuleT(delta, sigma, n_samples_x1=13, n_samples_x2=17):
    x1, x2 = genereDonnees(delta, sigma, n_samples_x1, n_samples_x2)
    return calculeT(x1, x2)

delta = 0.1
sigma = np.sqrt(1)
print(f"T pour delta={delta} et sigma={sigma} : {simuleT(delta, sigma)}")

"""## **2.3** Écrire une fonction `puissT` qui prend en entrée les valeurs de $\Delta$, $\sigma^2$, $\alpha$ et $N$ et qui fait les choses suivantes :
* elle simule $N$ valeurs de $T$ indépendantes;
* elle calcule et renvoie le nombre de fois où $T\ge \Phi_{m+n-2}^{-1}(1-\alpha)$
"""

def puissT(delta, sigma, alpha, n_simulations):
    n_rejections = 0

    c = stats.t.ppf((1-alpha), (13+17-2))

    for _ in range(n_simulations):
        if simuleT(delta, sigma) >= c:
            n_rejections += 1

    return n_rejections / n_simulations

"""## **2.4** En utilisant cette fonction pour $\sigma^2=20$ et $N=10^3$, approcher les valeurs de $\beta(\theta)$ pour les $16$ valeurs entières de $\Delta$ entre $0$ et $15$. Représenter graphiquement ces approximations en fonction de $\Delta$.

## **2.5** Même question pour $\sigma^2 = 30$.

## **2.6** Même question pour $\sigma^2 = 40$.
"""

DELTAS = range(16)
ALPHA = 0.05
SIGMAS = [20, 30, 40]

RESULTS = {}

def plot_experience(results, sigmas):
    traces = []
    for exp_name, exp_value in results.items():
        for sigma, value in zip(sigmas, exp_value):
            traces.append(
                go.Scatter(
                    y=value,
                    mode='lines',
                    name=f'sigma={sigma} ({exp_name})'
                )
            )

    fig = go.Figure(
        data=traces,
        layout={
            'legend': {
                'orientation': 'v'
            },
            'title': f"étude de la puissance du test en fonction de delta",
            'xaxis_title': "delta (mu2 - mu1)",
            'yaxis_title': f"puissance du test"
        }
    )
    fig.show()

def run_experience_1(deltas, sigmas, alpha, n_simulations):
    results = []

    for sigma in sigmas:
        result = []
        for delta in deltas:
            result.append(puissT(delta, np.sqrt(sigma), alpha, n_simulations))
        results.append(result)

    return results

n_simulations = 10**3
exp_name = f"exp1 : N={n_simulations}"
RESULTS[exp_name] = run_experience_1(DELTAS, SIGMAS, ALPHA, n_simulations)

plot_experience(RESULTS, SIGMAS)

"""## **2.7** Que peut-on faire pour améliorer ces approximations ? Le faire, et constater le résultat.

* On augmente le nombre de simulations
"""

n_simulations = 10**4
exp_name = f"exp1 : N={n_simulations}"
RESULTS[exp_name] = run_experience_1(DELTAS, SIGMAS, ALPHA, n_simulations)

plot_experience(RESULTS, SIGMAS)

"""# **Partie 3 : calcul d'une $p$-value par une méthode de permutation Monte-Carlo**

## **3.1** Écrire une fonction approxP [...]
"""

def approxP(x1, x2, t_obs, n_permutations):
    n_rejections = 0
    data = np.concatenate((x1, x2))

    for _ in range(n_permutations):
        data_shuffle = resample(data)
        new_x1, new_x2 = data_shuffle[:len(x1)], data_shuffle[len(x1):]

        if calculeT(new_x1, new_x2) > t_obs:
            n_rejections += 1

    return n_rejections / n_permutations

"""## **3.2** * En quelques lignes, expliquer pourquoi approxP permet d'approcher la p-value du test.

Une vue fréquentiste sur un test de taille $\alpha$ est de considérer qu'on doit conserver l'hypothèse nulle $H_0$ dans une proportion plus petite que $\alpha$ lorsqu'on répète l'observation des variables aléatoires un grand nombre de fois.

De la même façon, une vue fréquentiste sur la $p$-valeur est la proportion exacte de conservation de $H_0$ si on répète l'observation des variables aléatoires un grand nombre de fois.

On peut donc estimer la $p$-valeur si on arrive à obtenir un grand nombre de nouvelles observations des variables aléatoires du problème. Pour se faire, on se place sous $H_0$, et on obtient une distribution de probabilité commune à toutes nos variables aléatoires. On peut donc légitimement considérer qu'une permutation de nos observations constitue de nouvelles observations tout aussi probables puisque les VA sont indépendantes.

On construit donc un estimateur $\hat{p}$ en comptant le nombre de fois où on conserve $H_0$ après permutation de nos observations.

$\hat{p} = \frac{1}{n}\sum_{i=1}^{n}\delta(T^*_i > t_{obs})$

Les $T^*$ suivent une même loi et sont indépendants, ainsi
d'après la loi des grands nombres, pour $n \rightarrow +\infty$ on a $\hat{p} \rightarrow \textbf{E}\Big(\delta(T^* > t_{obs})\Big) = P\big(T^* > t_{obs}\big) = P(T > t_{obs}) = p$

$\square$

## **3.3** Rappeler comment on prend une décision en fonction de la valeur de la $p$-value et de la taille $\alpha$ du test.

On rejète l'hypothèse nulle si on a $\alpha > p$.

## **3.4** Approcher la $p$-value du test sur les données qui nous intéresse par cette méthode avec $K=10^4$. Quelle est la décision que l'on prend ici ?
"""

t_obs = calculeT(x1, x2)
print(f"approximation de la p-value : {approxP(x1, x2, t_obs, 10**4)}")
print(f"vraie p-value : {calculePvalue(t_obs, student_law_degree)}")

"""## **Partie 4 : Étude la puissance du test mis en place dans la partie 3**

### **4.1** En s'inspirant de la partie 2, écrire une fonction `puiss3` qui prend en entrée les valeurs de $\Delta$, $\sigma^2$, $\alpha$, $K$ et $N$ et qui fait les choses suivantes:
* elle simule $N$ jeux de données suivant (1) et (2);
* elle calcule, sur chacun de $N$ jeux de données, une approximation de la $p$-value à l'aide de `approxT` avec $K$ permutations indépendantes;
* elle compte le nombre de fois où ces $N$ $p$-value sont inférieures à $\alpha$;
* elle renvoie la fréquence où $p<\alpha$ parmi ces $N$ valeurs de $p$.
"""

def puiss3(delta, sigma, alpha, n_permutations, n_simulations):
    n_rejections = 0

    for _ in range(n_simulations):
        x1, x2 = genereDonnees(delta, sigma)
        t_obs = calculeT(x1, x2)

        p_value = approxP(x1, x2, t_obs, n_permutations)
        if p_value < alpha:
            n_rejections += 1

    return n_rejections / n_simulations

"""### **4.2** En utilisant cette fonction pour $\sigma^2=20$, $N=10^3$ et $K=400$, approcher les valeurs de $\beta_3(\theta)$ pour les $16$ valeurs entières de $\Delta$ entre $0$ et $15$. Représenter graphiquement ces approximations en fonction de $\Delta$, ainsi que $\beta(\theta)$ tel que calculé dans la partie 2. On représentera les deux courbes dans deux couleurs différentes.
### **4.3** Même question pour $\sigma^2=30$.
### **4.4** Même question pour $\sigma^2=40$.
"""

def run_experience_2(deltas, sigmas, alpha, n_permutations, n_simulations):
    results = []

    for sigma in sigmas:
        result = []
        for delta in deltas:
            result.append(puiss3(delta, sigma, alpha, n_permutations, n_simulations))
        results.append(result)

    return results

n_simulations = 10
n_permutations = 400

exp_name = f"exp2 : K={n_permutations}, N={n_simulations}"
RESULTS[exp_name] = run_experience_2(DELTAS, SIGMAS, ALPHA, n_permutations, n_simulations)

plot_experience(RESULTS, SIGMAS)

# ---
# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
# L'EXECUTION DE CETTE CELLULE PREND AU MOINS 15 MINUTES !
# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
# ---

n_simulations = 10**3
n_permutations = 400

exp_name = f"exp2 : K={n_permutations}, N={n_simulations}"
RESULTS[exp_name] = run_experience_2(DELTAS, SIGMAS, ALPHA, n_permutations, n_simulations)

plot_experience(RESULTS, SIGMAS)

"""### **4.5** Quel est le test le plus puissant sous l'hypothèse gaussienne?

Sous hypothèse gaussienne, le test de Student est largement plus puissant que celui des permutations par une méthode de Monte Carlo. Ce résultat est parfaitement prévisible. La loi de Student modélise le comportement de deux distributions gaussiennes, il est donc évident que s'y l'on émet une hypothèse identique aux données réelles, notre test sera très proche de l'efficacité maximale théorique d'un test d'hypothèse. Avoir un oracle très renseigné est toujours une la solution optimale, mais elle soulève deux observations : 

* l'efficacité de notre test de Student sous une hypothèse complètement différente ne peut être prouvé. Nous n'avons aucune garanti sur notre capacité de généralisation.
* nous venons de réaliser un magnifique biais de confirmation dans les règles de l'art.

### **4.6** Peut-on raisonnablement faire quelque chose ici pour améliorer l'approximation de $\beta_3(\theta)$?

Théoriquement, si on effectue toutes les permutations possibles, on devrait obtenir la vraie valeur de la puissance du test $\beta_3(\Theta)$. Une solution, très coûteuse en temps puisque le nombre de permutations possibles $M = \Big(\begin{array}{c} m+n \\  m \end{array} \Big)$ soit $M = \frac{(n+m)!}{n!m!}$
"""

n_simulations = 10
n_permutations = 4000

exp_name = f"exp2 : K={n_permutations}, N={n_simulations}"
RESULTS[exp_name] = run_experience_2(DELTAS, SIGMAS, ALPHA, n_permutations, n_simulations)

plot_experience(RESULTS, SIGMAS)

"""## **Partie 5 : amélioration de l'approximation**

## **5.1** Décrire en quelques lignes quel est l'objectif de l'article en question.

## **5.2** Quelle est l'idée de l'algorithme ?

## **5.3** Implémenter l'algorithme.
"""

def puiss3_bis(delta, sigma, alpha, n_permutations, n_simulations):
    n_rejections = 0

    for _ in range(n_simulations):
        x1, x2 = genereDonnees(delta, sigma, 8, 4)
        t_obs = calculeT(x1, x2)

        p_value = approxP(x1, x2, t_obs, n_permutations)
        if p_value < alpha:
            n_rejections += 1

    return n_rejections / n_simulations

###
# vars
###

deltas = [0.5, 1, 1.5, 2]
alpha = 0.05
sigmas = [1]

RESULTS = {}

n_simulations = 4000
n_permutations = [99, 79, 59, 39, 19]

for n_permutation in n_permutations:
    for sigma in sigmas:
        for delta in deltas:
            exp_name = (delta, n_permutation)
            RESULTS[exp_name] = puiss3_bis(delta, sigma, alpha, n_permutation, n_simulations)

    print(f"{n_permutation} done")

same_k = []
for k, v in RESULTS.items():
    plt.scatter(1/k[1], v, label=f"{k}", color='k')
plt.show()

from sklearn.linear_model import Ridge

(delta, n_permutation)

lambda get_by_delta x:

for
clf = Ridge(alpha=1)
clf.fit()

x1 = x1[:8]
x2 = x2[:4]
